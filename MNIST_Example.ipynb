{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wie verläuft ein Machine Learning Projekt?\n",
    "8 Schritte bis zum Anwenden des neuen Systems:\n",
    "\n",
    "1. Identifizieren des Problems; Betrachten des Großen-Ganzen\n",
    " * Hinterfrage die Aufgabenstellung\n",
    " * Sprich mit Experten, worin der Mehrwert der neuen Anwendung besteht\n",
    " * Wie wird die Anwendung anschließend benutzt (für weitere Machine Learning Systeme/Datenanalyse/Präsentation/...)\n",
    " * Welche Ergebnisse gibt es bislang? Welche Aspekte sind scheinbar von belang?\n",
    " \n",
    " für die Entwicklung direkt von Belang und resultierend aus den ersten Stichpunkten:\n",
    " * Was für Machine Learning Modelle sollten genutzt werden? (supervised/unsupervised, online/offline, ...)\n",
    " * Wie sollte die Performance gemessen werden? Wie sollte die Fehleranalyse von statten gehen?\n",
    " * Wie gut sollte die Performance für das Ziel sein?\n",
    " * Was für Probleme könnten auftreten? Gibt es bereits Erfahrungen auf diesem Gebiet?\n",
    " * Wie könnte das Problem manuell gelöst werde?\n",
    " * Vermerke und verifiziere, wenn möglich, Annahmen.\n",
    "\n",
    "2. Laden der Daten (wenn möglich, automatisieren)\n",
    " * Auflisten der Daten (welche werden gebraucht, wieviele werden gebraucht)\n",
    " * Finden und Dokumentieren, woher die Daten bezogen werden können\n",
    " * Speicherbedarf überprüfen\n",
    " * Zertifikate und Erlaubnisse überprüfen und gegebenenfalls anfordnern\n",
    " * Workspace erstellen\n",
    " * Daten laden\n",
    " * Konvertieren der Daten zum verarbeiten in Machine Learning Algorithmen (Daten nicht ändern)\n",
    " * Anonymisieren, fall noch notwenig\n",
    " * Größe und Datentypen überprüfen (Zeitserien, Beispiele, Geografische Daten, ...)\n",
    " * Extrahiere ein Testset und entferne es aus den Trainingsdaten (diese Daten dienen ausschließlich zum Testen!)\n",
    "\n",
    "3. Daten betrachten um erste Einsichten zu erlangen\n",
    " - Erstellen einer Kopie der Trainingsdaten\n",
    " - Betrachte jedes Attribut der Daten (Name, Datentyp, fehlende Daten?, Rauschen?, Outlier?, potenziell Wichtig?, Verteilung(Gauss, Uniform, Logarithmisch))\n",
    " - Für supervised learning identifiziere die Ziel-Attribute\n",
    " - Visualisiere die Daten\n",
    " - Wie ist die Correlation zwischen Attributen?\n",
    " - Gibt es Transformationen, die durchzuführen sind?\n",
    " - Welche Extra-Daten könnten nützlich sein?\n",
    " - Dokumentation\n",
    "\n",
    "4. Daten vorbereiten um durch Machine Learning Algorithmen die hintergründigen Informationen besser extrahieren zu können\n",
    " Wichtig! Auf Kopien arbeiten. Für jede Tranlation Funktionen schreiben.\n",
    " - Daten säubern (entferne Outlier, Fülle fehlende Daten auf (mit mean oder 0) oder lösche die Zeilen/Spalten\n",
    " - Wähle Attribute aus (entferne 'unnütze' Feature (könnten auch nützlich sein, ohne das man es weiß))\n",
    " - Erstelle weitere Attribute (durch Kombination bzw Translation von bestehenden Attributen)\n",
    " - Extrahiere Attribute (bsp. Datum/Zeit, Kategorien->in Zahlenwerte)\n",
    " - Standartisiere oder Normalisiere Attribute\n",
    "\n",
    "5. Probiere verschieden Modelle und vermerke die Besten (nach Möglichkeit automatisieren)\n",
    " - Trainiere verschiedene Standard-Modelle\n",
    " - Messe und vergleiche die Performance der Modelle\n",
    " - Analysiere die wichtigsten Variablen für jedes Modell\n",
    " - Analysiere die Fehler?\n",
    " - Nutze die Erkenntnisse für eine kurze Feature-Selektion und Konfiguriere einige Modelle neu\n",
    " - Wiederhole diesen Schritt bis 3-5 Modelle hervorstechen\n",
    "\n",
    "6. Konfiguriere und Kombiniere die Modelle, um die best mögliche Lösung zu finden (nach Möglichkeit automatisieren)\n",
    " - Finde die besten Hyperparameter der Modelle durch cross-validation\n",
    " - Kombinieren der besten Modelle um ein noch besseres Ergebnis zu erlangen\n",
    " - Messen der Performanz des endgültigen Aufbaus\n",
    "\n",
    "7. Präsentiere die Lösung\n",
    "8. Verwende, Überprüfe und Warte das neue System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COL_NAMES': ['label', 'data'],\n",
       " 'DESCR': 'mldata.org dataset: mnist-original',\n",
       " 'data': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " 'target': array([ 0.,  0.,  0., ...,  9.,  9.,  9.])}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Print a number**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4odQ4odQ4odQ4odQ4odQ4odQ4odQvwGkSMoFGWn6ugAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa022fbb320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should be 7.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "one_digit = X[42000]\n",
    "image_one_digit = one_digit.reshape(28,28)\n",
    "\n",
    "plt.imshow(image_one_digit, cmap = matplotlib.cm.binary, interpolation = \"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Should be\", y[42000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cut the dataset into test and training sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "\n",
    "#shuffle the training set\n",
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
